# general parameters
seed: 42
experiment: debug_snn

# task parameters
task:
  type: reacher2
  params:
    max_episode_steps: 200
    render: false
    moving_target: 0.0

# general parameters
general:
  model:
    params:
      hidden_dim: 256
  optim:
    type: adam
    params:
      lr: 0.0005
  learning:
    params:
      batch_size: 1_024
      n_batches: 100
      unroll_steps: 3
      warmup_steps: 8
      max_norm: 50

# policy model parameters
policy:
  model:
    type: RSNNcs
    params:
      hidden_dim: 256
      num_rec_layers: 0
      num_ff_layers: 2
      repeat_input: 10
      out_style: last
      dt: 0.002
      lowerBoundL2Strength: 0.0
      upperBoundL2Strength: 1.0
      weightL2Strength: 0.0
      connection_dims: null
      nu: 50
      #flif_kwargs:
        # train_V_tau: True
        # train_I_tau: True
      readout_kwargs:
        # train_V_tau: True
        # train_I_tau: False
        n_pop: 50
  optim:
    type: smorms3
    params:
      lr: 0.0005
  learning:
    params:
      deterministic_transition: False

# transition model parameters
transition:
  model:
    type: rnnPBadapt
    params:
      act_func: lrelu
      num_rec_layers: 1
      num_ff_layers: 1

# training parameters
memory_size: 3_000
total_env_steps: 1_000_000
episodes_per_iteration: 20
evaluate: True
evaluate_every_n_iterations: 10

# plotting parameters
animate: True
animate_unroll: 10
record_every_n_iterations: 10
record_first_n_episodes: 5

# logging parameters
project: ann-control
entity: jhuebotter
