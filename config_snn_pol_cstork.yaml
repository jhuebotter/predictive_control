# general parameters
seed: 42
experiment: dev_policy_snn

# task parameters
task:
  type: reacher2
  params:
    max_episode_steps: 200
    render: false
    moving_target: 0.0

# general parameters
general:
  model:
    params:
      hidden_dim: 512
  optim:
    type: smorms3
    params:
      lr: 0.0005
  learning:
    params:
      batch_size: 512
      n_batches: 25
      warmup_steps: 5
      max_norm: 30

# policy model parameters
policy:
  model:
    type: RSNNcs
    params:
      hidden_dim: 1024
      num_rec_layers: 0
      num_ff_layers: 2
      repeat_input: 8
      out_style: last
      dt: 0.002
      lowerBoundL2Strength: 0.0
      upperBoundL2Strength: 1.0
      weightL2Strength: 0.0
      connection_dims: 0
      nu: 50
      activation_kwargs:
        act_fn: sigmoidspike
        beta: 100.0
        gamma: 1.0
      flif_kwargs:
        reset: sub
        # train_V_tau: True
        # train_I_tau: True
      readout_kwargs:
        # train_V_tau: True
        # train_I_tau: False
        n_pop: 50
  optim:
    params:
      lr: 0.0005
  learning:
    params:
      deterministic_transition: True

# transition model parameters
transition:
  model:
    type: rnnPBadapt
    params:
      activation_kwargs:
        act_fn: lrelu
      num_rec_layers: 1
      num_ff_layers: 1
  learning:
    params:
      autoregressive: True
      unroll_steps: 1

# training parameters
memory_size: 1_000
total_env_steps: 500_000
episodes_per_iteration: 25
evaluate: True
evaluate_every_n_iterations: 1
load_baseline_transition: False

# plotting parameters
animate: False
animate_unroll: 20
record_every_n_iterations: 20
record_first_n_episodes: 5

# logging parameters
project: ann-control
entity: jhuebotter
